# SpÃ©cification : Base de DonnÃ©es Graph EmbarquÃ©e et LLM Local pour Hoddor

**Version:** 2.0
**Date:** 2025-10-20
**Status:** Draft
**Auteurs:** Ã‰quipe Hoddor

---

## Table des MatiÃ¨res

1. [Vue d'ensemble](#1-vue-densemble)
2. [Contexte et Motivation](#2-contexte-et-motivation)
3. [Stack Technologique](#3-stack-technologique)
4. [Architecture Globale](#4-architecture-globale)
5. [Composants Principaux](#5-composants-principaux)
6. [ModÃ¨le de DonnÃ©es](#6-modÃ¨le-de-donnÃ©es)
7. [Interfaces et API](#7-interfaces-et-api)
8. [Flux RAG Complet](#8-flux-rag-complet)
9. [SÃ©curitÃ© et Chiffrement](#9-sÃ©curitÃ©-et-chiffrement)
10. [Performance et ScalabilitÃ©](#10-performance-et-scalabilitÃ©)
11. [Plan d'ImplÃ©mentation](#11-plan-dimplÃ©mentation)
12. [RÃ©fÃ©rences](#12-rÃ©fÃ©rences)

---

## 1. Vue d'ensemble

### 1.1 Objectif

IntÃ©grer dans Hoddor une **solution complÃ¨te de mÃ©moire pour LLM**, entiÃ¨rement locale et chiffrÃ©e, comprenant :

- ğŸ§  **Graph Database** (CozoDB) : Stockage de connaissances avec relations sÃ©mantiques
- ğŸ”¢ **Vector Search** : Recherche par similaritÃ© (embeddings)
- ğŸ¤– **LLM Local** (WebLLM) : InfÃ©rence dans le navigateur
- ğŸ’¬ **RAG Pipeline** : Orchestration Retrieval-Augmented Generation
- ğŸ”’ **Zero-Knowledge** : Chiffrement end-to-end, aucune donnÃ©e externe

### 1.2 Principe de Fonctionnement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Question Utilisateur                                 â”‚
â”‚           â†“                                           â”‚
â”‚  Embedding (text â†’ vector)                           â”‚
â”‚           â†“                                           â”‚
â”‚  Graph Search (similaritÃ© + relations)               â”‚
â”‚           â†“                                           â”‚
â”‚  Contexte enrichi (dÃ©chiffrÃ©)                        â”‚
â”‚           â†“                                           â”‚
â”‚  LLM Local gÃ©nÃ¨re rÃ©ponse                            â”‚
â”‚           â†“                                           â”‚
â”‚  Sauvegarde interaction (chiffrÃ©e)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     â†‘ TOUT RESTE DANS LE NAVIGATEUR â†‘
```

### 1.3 Valeur AjoutÃ©e

| Aspect | Solution Actuelle | Avec Graph + LLM Local |
|--------|-------------------|------------------------|
| **Privacy** | ChiffrÃ© mais LLM externe | 100% local, zero data leak |
| **CoÃ»ts** | API calls payantes | Gratuit aprÃ¨s download |
| **Offline** | Impossible sans LLM | Fonctionne offline complet |
| **Latence** | Network + API | Local (plus rapide sur petits modÃ¨les) |
| **Contexte** | MÃ©moire limitÃ©e | Graph illimitÃ© avec relations |
| **GDPR** | DÃ©pend du provider | Compliant par design |

### 1.4 Contraintes Techniques

- **EmbarquÃ©** : Tout dans le navigateur (WASM + WebGPU)
- **Zero-knowledge** : Pas de serveur externe
- **Architecture hexagonale** : Ports & Adapters
- **Storage OPFS** : Origin Private File System
- **Performance** : < 3s pour requÃªte RAG complÃ¨te
- **ScalabilitÃ©** : Support 100K+ nÅ“uds

---

## 2. Contexte et Motivation

### 2.1 Ã‰volution du Besoin

**Phase 1 (Actuel)** : Hoddor = Vault chiffrÃ©
```
Stockage sÃ©curisÃ© âœ…
â””â”€ Mais : DonnÃ©es isolÃ©es, pas de relations
```

**Phase 2 (Cette spec)** : Hoddor = Memory Layer pour LLM
```
Graph Database âœ…
â””â”€ Relations sÃ©mantiques
LLM Local âœ…
â””â”€ InfÃ©rence privÃ©e
RAG Pipeline âœ…
â””â”€ Contexte enrichi
```

### 2.2 Pourquoi Graph + LLM Local ?

#### ProblÃ¨me : LLM Cloud classique
```
User Question
    â†“
[HODDOR] DonnÃ©es chiffrÃ©es locales
    â†“
[CLOUD] DÃ©chiffrÃ© + envoyÃ© Ã  OpenAI/Claude
    â†“
âŒ Privacy compromise
âŒ CoÃ»ts rÃ©currents
âŒ DÃ©pendance rÃ©seau
```

#### Solution : Graph + LLM Local
```
User Question
    â†“
[HODDOR Graph] Recherche locale chiffrÃ©e
    â†“
[WebLLM] InfÃ©rence locale (WebGPU)
    â†“
âœ… Zero data leak
âœ… Gratuit
âœ… Offline-capable
```

### 2.3 Cas d'Usage Cibles

1. **Assistant Personnel PrivÃ©**
   - MÃ©moire des prÃ©fÃ©rences, habitudes, contexte
   - Suggestions personnalisÃ©es sans tracking

2. **Knowledge Base Entreprise**
   - Documentation interne, procÃ©dures
   - Search sÃ©mantique + Q&A

3. **Note-Taking Intelligent**
   - Relations automatiques entre notes
   - Retrieval contextuel

4. **Healthcare / Legal**
   - DonnÃ©es sensibles (RGPD, HIPAA)
   - Zero risque de fuite

---

## 3. Stack Technologique

### 3.1 Comparatif des Options

#### Graph Database

| Solution | Embedded | WASM | Vector | Status | Verdict |
|----------|----------|------|--------|--------|---------|
| **KuzuDB** | âœ… | âœ… | âœ… | âŒ AbandonnÃ© (Oct 2025) | ğŸš« Non viable |
| **petgraph** | âœ… | âœ… | âŒ | âœ… Actif | âš ï¸ Trop basique |
| **CozoDB** | âœ… | âœ… | âœ… HNSW | âœ… Actif | âœ… **CHOISI** |

**Justification CozoDB :**
- ConÃ§u pour LLM ("The hippocampus for AI")
- Datalog (requÃªtes puissantes)
- Transactionnel (ACID)
- Multi-modÃ¨le (Graph + Relationnel + Vector)
- Performance : 100K+ QPS

#### LLM Local

| Solution | ModÃ¨les | WebGPU | API | Verdict |
|----------|---------|--------|-----|---------|
| **WebLLM** | Llama, Phi, Mistral, Gemma | âœ… | OpenAI-compatible | âœ… **CHOISI** |
| **Transformers.js** | Distilled (petits) | âš ï¸ | Custom | âš ï¸ Backup |
| **ONNX Runtime** | Custom | âš ï¸ | Custom | âš ï¸ Complexe |

**Justification WebLLM :**
- Projet MLC-AI (actif, mature)
- WebGPU acceleration (10x plus rapide que WASM seul)
- ModÃ¨les variÃ©s (2GB - 8GB)
- API compatible OpenAI (facile Ã  intÃ©grer)
- Streaming support

#### Embedding Model

| Solution | Taille | QualitÃ© | Vitesse | Verdict |
|----------|--------|---------|---------|---------|
| **all-MiniLM-L6-v2** | 25MB | Bonne | Rapide | âœ… **PoC** |
| **BGE-small** | 50MB | Meilleure | Moyenne | âœ… **Production** |
| **E5-base** | 120MB | Excellente | Lente | âš ï¸ Option |

**Justification all-MiniLM-L6-v2 (PoC) :**
- LÃ©ger (25MB)
- Rapide (10-50ms)
- QualitÃ© suffisante pour dÃ©mo
- Transformers.js natif

### 3.2 Stack Finale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HODDOR GRAPH + LLM STACK                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Graph Database    â”‚  CozoDB 0.7+                   â”‚
â”‚  LLM Engine        â”‚  WebLLM (MLC-AI)               â”‚
â”‚  Embedding         â”‚  Transformers.js               â”‚
â”‚  Storage           â”‚  OPFS                          â”‚
â”‚  Encryption        â”‚  Age (existing)                â”‚
â”‚  Language (Core)   â”‚  Rust (WASM)                   â”‚
â”‚  Language (LLM)    â”‚  TypeScript                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 ModÃ¨les RecommandÃ©s

#### Phase PoC
```
LLM:       Phi-3.5-mini-instruct (2GB)
Embedder:  all-MiniLM-L6-v2 (25MB)
Total:     ~2GB download (one-time)
```

#### Phase Production
```
LLM Options:
  - Small:  Phi-3.5-mini (2GB)      â†’ Rapide, basique
  - Medium: Llama-3.2-3B (2GB)      â†’ Ã‰quilibrÃ©
  - Large:  Mistral-7B (4GB)        â†’ Meilleur qualitÃ©

Embedder:
  - BGE-small-en (50MB)             â†’ Meilleure qualitÃ©
```

---

## 4. Architecture Globale

### 4.1 Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APPLICATION LAYER                        â”‚
â”‚  (React/Vue UI - Playground + Extensions)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RAG ORCHESTRATION LAYER                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  RAG Pipeline Manager                               â”‚  â”‚
â”‚  â”‚  â”œâ”€ Question â†’ Embedding                            â”‚  â”‚
â”‚  â”‚  â”œâ”€ Graph search (context retrieval)                â”‚  â”‚
â”‚  â”‚  â”œâ”€ Prompt construction                             â”‚  â”‚
â”‚  â”‚  â”œâ”€ LLM inference                                    â”‚  â”‚
â”‚  â”‚  â””â”€ Response post-processing                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Embedding Model â”‚         â”‚   WebLLM Engine  â”‚         â”‚
â”‚  â”‚ (Transformers)  â”‚         â”‚  (Phi/Llama/etc) â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   HODDOR CORE (WASM)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Domain Layer (Rust)                    â”‚  â”‚
â”‚  â”‚  â”œâ”€ domain/graph/                                   â”‚  â”‚
â”‚  â”‚  â”‚  â”œâ”€ types.rs      (Node, Edge, Embedding)       â”‚  â”‚
â”‚  â”‚  â”‚  â”œâ”€ operations.rs (Business logic)              â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€ rag.rs        (RAG-specific logic)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â†“                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Ports Layer (Rust)                     â”‚  â”‚
â”‚  â”‚  â”œâ”€ ports/graph.rs    (trait GraphPort)            â”‚  â”‚
â”‚  â”‚  â”œâ”€ ports/embedding.rs (trait EmbeddingPort)       â”‚  â”‚
â”‚  â”‚  â””â”€ ports/llm.rs      (trait LLMPort)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â†“                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            Adapters Layer (Rust)                    â”‚  â”‚
â”‚  â”‚  â”œâ”€ adapters/wasm/cozo_graph.rs                    â”‚  â”‚
â”‚  â”‚  â”œâ”€ adapters/wasm/transformers_embedding.rs        â”‚  â”‚
â”‚  â”‚  â””â”€ adapters/wasm/webllm_adapter.rs                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               INFRASTRUCTURE LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   CozoDB     â”‚  â”‚   WebLLM     â”‚  â”‚ Transformers.jsâ”‚  â”‚
â”‚  â”‚   (Graph)    â”‚  â”‚ (Inference)  â”‚  â”‚  (Embeddings)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â†“                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           OPFS (Origin Private File System)         â”‚  â”‚
â”‚  â”‚  â”œâ”€ Graph data (encrypted with Age)                â”‚  â”‚
â”‚  â”‚  â”œâ”€ Model cache (LLM ~2-4GB)                       â”‚  â”‚
â”‚  â”‚  â””â”€ Embeddings cache                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 SÃ©paration des ResponsabilitÃ©s

| Layer | ResponsabilitÃ© | Technologies |
|-------|----------------|--------------|
| **Application** | UI, UX, interactions utilisateur | React/Vue/Svelte |
| **Orchestration** | RAG pipeline, coordination | TypeScript |
| **Domain** | Logique mÃ©tier, rÃ¨gles | Rust |
| **Ports** | Interfaces abstraites | Rust traits |
| **Adapters** | ImplÃ©mentations concrÃ¨tes | Rust + JS glue |
| **Infrastructure** | Libraries externes | CozoDB, WebLLM, etc. |

### 4.3 Flux de DonnÃ©es

```
Question (Text)
    â†“
[Embedding Model] â†’ Vector (Float32Array)
    â†“
[Graph Port] â†’ RAG Search (Datalog)
    â†“
[Encryption Port] â†’ Decrypt context
    â†“
[LLM Port] â†’ Generate response
    â†“
[Graph Port] â†’ Save interaction
    â†“
Response (Text)
```

---

## 5. Composants Principaux

### 5.1 Graph Database (CozoDB)

**RÃ´le :** Stockage et recherche de la mÃ©moire

**FonctionnalitÃ©s :**
- Stockage nodes (mÃ©moires) + edges (relations)
- Vector search (HNSW) : SimilaritÃ© cosine
- Graph traversal : BFS, DFS, shortest path
- Datalog queries : RequÃªtes complexes
- Transactions ACID : CohÃ©rence des donnÃ©es

**SchÃ©mas :**
```
Relations (Datalog):
  - memory (nodes)
  - relation (edges)

Index:
  - HNSW sur embeddings (cosine similarity)
  - B-tree sur vault_id, node_type, labels
```

**Performance Cible :**
- Create node: < 10ms
- Vector search (top 10): < 50ms
- Graph traversal (depth 2): < 100ms

### 5.2 LLM Local (WebLLM)

**RÃ´le :** GÃ©nÃ©ration de rÃ©ponses

**ModÃ¨les SupportÃ©s :**
- Phi-3.5 (2GB) : Rapide, qualitÃ© correcte
- Llama-3.2-3B (2GB) : Ã‰quilibrÃ©
- Mistral-7B (4GB) : Meilleure qualitÃ©
- Gemma-2B (2GB) : Alternative

**Modes d'ExÃ©cution :**
```
1. WebGPU (prÃ©fÃ©rÃ©)
   â””â”€ 10x plus rapide que WASM
   â””â”€ NÃ©cessite GPU compatible

2. WASM (fallback)
   â””â”€ Compatible partout
   â””â”€ Plus lent (acceptable pour PoC)
```

**Performance Cible :**
```
WebGPU Mode:
  - Load time (from cache): 5-10s
  - Inference (100 tokens): 500-2000ms
  - Streaming: Oui

WASM Mode:
  - Load time: 10-15s
  - Inference (100 tokens): 2000-5000ms
  - Streaming: Oui
```

**API :**
- Compatible OpenAI Chat Completions
- Streaming support
- Temperature, top_p, max_tokens, etc.

### 5.3 Embedding Model (Transformers.js)

**RÃ´le :** Conversion texte â†’ vecteur

**ModÃ¨les :**
```
PoC:        all-MiniLM-L6-v2 (384 dimensions, 25MB)
Production: BGE-small-en (384 dimensions, 50MB)
Advanced:   E5-base (768 dimensions, 120MB)
```

**FonctionnalitÃ©s :**
- Mean pooling
- Normalization (L2)
- Batch processing

**Performance Cible :**
- Single text: 10-50ms
- Batch (10 texts): 50-200ms

### 5.4 RAG Orchestrator

**RÃ´le :** Coordination du flux RAG

**Ã‰tapes :**
1. **Embedding** : Question â†’ Vector
2. **Retrieval** : Graph search + relations
3. **Decrypt** : DÃ©chiffrer contexte pertinent
4. **Prompt** : Construire prompt avec contexte
5. **Generate** : LLM inference
6. **Save** : Stocker interaction

**Configuration :**
```
RAG Parameters:
  - top_k: 3-10 (nombre de rÃ©sultats)
  - similarity_threshold: 0.5-0.8
  - relation_depth: 0-3 (profondeur graph)
  - max_context_tokens: 1000-4000
```

---

## 6. ModÃ¨le de DonnÃ©es

### 6.1 Structure des NÅ“uds

```
Node {
  id: UUID
  type: String (memory, entity, event, concept, conversation)
  vault_id: String
  namespace?: String
  labels: [String]
  embedding?: [Float; 384]
  encrypted_content: Bytes (age encryption)
  content_hmac: String (integrity)
  metadata: {
    content_size: Int
    version: Int
    expires_at?: Timestamp
  }
  created_at: Timestamp
  updated_at: Timestamp
  accessed_at: Timestamp
  access_count: Int
}
```

### 6.2 Structure des Relations

```
Edge {
  id: UUID
  from_node: UUID
  to_node: UUID
  edge_type: String (relates_to, is_a, part_of, etc.)
  vault_id: String
  weight: Float (0.0-1.0)
  bidirectional: Bool
  encrypted_context?: Bytes
  created_at: Timestamp
}
```

### 6.3 Types PrÃ©dÃ©finis

**Node Types :**
- `memory` : MÃ©moire gÃ©nÃ©rale
- `entity` : EntitÃ© (personne, lieu, objet)
- `event` : Ã‰vÃ©nement datÃ©
- `concept` : Concept abstrait
- `conversation` : Historique LLM
- `document` : Document structurÃ©
- `preference` : PrÃ©fÃ©rence utilisateur

**Edge Types :**
- `relates_to` : Relation gÃ©nÃ©rique
- `is_a` : Type/Classe
- `part_of` : Composition
- `located_in` : Localisation
- `happened_at` : Temporel
- `caused_by` : CausalitÃ©
- `references` : RÃ©fÃ©rence

### 6.4 Exemples de Graph

**MÃ©moire d'un Assistant Personnel :**
```
[User] â”€â”€prefersâ”€â”€> [Coffee:black_no_sugar]
  â”‚
  â”œâ”€â”€isâ”€â”€> [Vegetarian]
  â”‚
  â””â”€â”€lives_inâ”€â”€> [Paris]
      â”‚
      â””â”€â”€nearâ”€â”€> [Eiffel_Tower]
```

**Knowledge Base :**
```
[Doc:Architecture] â”€â”€discussesâ”€â”€> [Concept:Hexagonal]
                                        â”‚
                                        â”œâ”€â”€related_toâ”€â”€> [Concept:Ports]
                                        â””â”€â”€related_toâ”€â”€> [Concept:Adapters]
```

---

## 7. Interfaces et API

### 7.1 Ports (Rust Traits)

#### GraphPort
```rust
trait GraphPort {
    // CRUD
    async fn create_node(...) -> Result<NodeId>;
    async fn get_node(...) -> Result<Option<Node>>;
    async fn update_node(...) -> Result<()>;
    async fn delete_node(...) -> Result<()>;

    async fn create_edge(...) -> Result<EdgeId>;
    async fn get_edges(...) -> Result<Vec<Edge>>;

    // Search
    async fn vector_search(...) -> Result<Vec<(Node, f64)>>;
    async fn traverse(...) -> Result<Vec<Node>>;
    async fn shortest_path(...) -> Result<Option<Vec<NodeId>>>;

    // RAG
    async fn rag_query(...) -> Result<RagResult>;
}
```

#### LLMPort
```rust
trait LLMPort {
    async fn load_model(model_id: &str) -> Result<()>;
    async fn generate(prompt: &str, config: GenerateConfig) -> Result<String>;
    async fn generate_stream(...) -> Result<Stream<String>>;
    fn is_loaded() -> bool;
    fn model_info() -> ModelInfo;
}
```

#### EmbeddingPort
```rust
trait EmbeddingPort {
    async fn embed(text: &str) -> Result<Vec<f32>>;
    async fn embed_batch(texts: Vec<&str>) -> Result<Vec<Vec<f32>>>;
    fn dimension() -> usize;
}
```

### 7.2 FaÃ§ade JavaScript

```typescript
// Graph API
interface GraphAPI {
  // Nodes
  createNode(vaultId: string, type: string, content: any, options?: NodeOptions): Promise<string>;
  getNode(vaultId: string, nodeId: string): Promise<Node | null>;
  updateNode(vaultId: string, nodeId: string, content: any): Promise<void>;
  deleteNode(vaultId: string, nodeId: string): Promise<void>;

  // Relations
  createEdge(vaultId: string, from: string, to: string, type: string, weight?: number): Promise<string>;
  getEdges(vaultId: string, nodeId: string, direction?: EdgeDirection): Promise<Edge[]>;

  // Search
  vectorSearch(vaultId: string, embedding: number[], options?: SearchOptions): Promise<SearchResult[]>;
  traverse(vaultId: string, startNode: string, options?: TraverseOptions): Promise<Node[]>;

  // RAG
  ragQuery(vaultId: string, query: RagQuery): Promise<RagResult>;
}

// LLM API
interface LLMAPI {
  loadModel(modelId: string, onProgress?: (progress: number) => void): Promise<void>;
  chat(messages: ChatMessage[], options?: ChatOptions): Promise<string>;
  chatStream(messages: ChatMessage[], onToken: (token: string) => void): Promise<void>;
  isReady(): boolean;
  getModelInfo(): ModelInfo;
}

// RAG Orchestrator
interface RAGOrchestrator {
  ask(vaultId: string, question: string, options?: RagOptions): Promise<RagResponse>;
  addMemory(vaultId: string, content: string, type: string, labels?: string[]): Promise<string>;
}
```

### 7.3 Types Principaux

```typescript
interface RagQuery {
  question: string;
  topK?: number;              // Default: 5
  similarityThreshold?: number; // Default: 0.7
  includeRelations?: boolean;  // Default: true
  relationDepth?: number;      // Default: 2
  nodeTypes?: string[];
  labels?: string[];
}

interface RagResult {
  memories: MemoryMatch[];
  relations: Edge[];
  contextForLLM: string;
  sourceIds: string[];
  metadata: {
    searchTime: number;
    inferenceTime: number;
    totalTokens: number;
  };
}

interface RagResponse {
  answer: string;
  sources: Node[];
  confidence: number;
  metadata: RagMetadata;
}
```

---

## 8. Flux RAG Complet

### 8.1 Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. QUESTION                                         â”‚
â”‚     User: "Comment j'aime mon cafÃ© ?"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. EMBEDDING                                        â”‚
â”‚     all-MiniLM-L6-v2: [0.23, -0.45, ...]           â”‚
â”‚     Time: ~20ms                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. GRAPH SEARCH (CozoDB)                           â”‚
â”‚     a) Vector similarity (HNSW)                     â”‚
â”‚        â†’ Top 5 similar nodes                        â”‚
â”‚     b) Graph traversal (Datalog)                    â”‚
â”‚        â†’ Relations (depth 2)                        â”‚
â”‚     c) Decrypt content (age)                        â”‚
â”‚     Time: ~50-100ms                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. CONTEXTE RÃ‰CUPÃ‰RÃ‰                               â”‚
â”‚     - "J'adore le cafÃ© noir sans sucre" (0.95)     â”‚
â”‚     - "Je prends un cafÃ© chaque matin" (0.87)      â”‚
â”‚     - Relations: prefers â†’ coffee_black            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. PROMPT CONSTRUCTION                             â”‚
â”‚     System: "You are an assistant..."              â”‚
â”‚     Context: "User preferences: ..."               â”‚
â”‚     Question: "Comment j'aime mon cafÃ© ?"          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. LLM INFERENCE (WebLLM)                          â”‚
â”‚     Model: Phi-3.5-mini                            â”‚
â”‚     Time: ~1-2s (WebGPU)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. RÃ‰PONSE                                          â”‚
â”‚     "Vous aimez le cafÃ© noir sans sucre."          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. SAUVEGARDE INTERACTION                          â”‚
â”‚     Create node: conversation                       â”‚
â”‚     Create edges: references sources               â”‚
â”‚     Update: access_count++                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Optimisations

**Cache Strategy :**
- Embeddings cache (LRU)
- Frequent queries cache
- Model loaded once (stay in memory)

**Lazy Loading :**
- Nodes chargÃ©s Ã  la demande
- Relations suivies progressivement

**Batch Processing :**
- Multiple embeddings en parallÃ¨le
- Transactions groupÃ©es

---

## 9. SÃ©curitÃ© et Chiffrement

### 9.1 Principe Zero-Knowledge

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TOUT CHIFFRÃ‰ DANS OPFS               â”‚
â”‚                                        â”‚
â”‚  Graph data (CozoDB)                  â”‚
â”‚  â”œâ”€ Nodes: encrypted_content (age)   â”‚
â”‚  â”œâ”€ Edges: encrypted_context (age)   â”‚
â”‚  â””â”€ HMAC: integrity verification     â”‚
â”‚                                        â”‚
â”‚  Models (cache)                       â”‚
â”‚  â”œâ”€ LLM weights (public, non chiffrÃ©)â”‚
â”‚  â””â”€ Embeddings (public, non chiffrÃ©) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ClÃ©s de chiffrement:
  vault_master_key (user password)
    â†“ HKDF
  graph_key (dÃ©rivÃ©e, 256 bits)
    â†“
  age::encrypt(content, graph_key)
```

### 9.2 Trade-offs Embeddings

**Option A : Embeddings Non ChiffrÃ©s** (RecommandÃ©)
- âœ… HNSW natif (rapide)
- âš ï¸ RÃ©vÃ¨le info sÃ©mantique
- ğŸ’¡ Acceptable si OPFS local

**Option B : Embeddings ChiffrÃ©s** (Paranoid mode)
- âœ… Zero fuite sÃ©mantique
- âŒ Pas de HNSW (dÃ©chiffrer tout)
- ğŸ’¡ TrÃ¨s lent, pour cas extrÃªmes

**Configuration :**
```typescript
interface EncryptionConfig {
  encryptEmbeddings: boolean; // Default: false
  hmacVerification: boolean;  // Default: true
  keyRotation?: number;       // Optional auto-rotation
}
```

### 9.3 Isolation

- **Par vault** : Chaque vault = clÃ© diffÃ©rente
- **Par origin** : OPFS isolÃ© par domaine
- **Pas de serveur** : Aucune donnÃ©e envoyÃ©e

---

## 10. Performance et ScalabilitÃ©

### 10.1 Objectifs

| MÃ©trique | Cible (PoC) | Cible (Production) |
|----------|-------------|---------------------|
| Load LLM (from cache) | < 10s | < 5s |
| Embedding (single) | < 50ms | < 20ms |
| Graph search (top 10) | < 100ms | < 50ms |
| LLM inference (100 tok) | < 2s (WebGPU) | < 1s |
| **RAG complet** | **< 3s** | **< 1.5s** |

### 10.2 ScalabilitÃ©

| Taille | NÅ“uds | Edges | StratÃ©gie | Latence Attendue |
|--------|-------|-------|-----------|------------------|
| **Petit** | < 10K | < 100K | Tout en mÃ©moire | < 50ms (search) |
| **Moyen** | 10K-100K | 100K-1M | Cache LRU | < 100ms |
| **Grand** | 100K-1M | 1M-10M | Lazy loading + index | < 200ms |

### 10.3 Benchmarks Cibles (PoC)

```
Environment:
  - Browser: Chrome 120+
  - GPU: Any WebGPU-compatible
  - Model: Phi-3.5-mini (2GB)
  - Graph: 10K nodes, 50K edges

Results:
  âœ“ Create node:              5ms
  âœ“ Vector search (top 10):   45ms
  âœ“ Graph traversal (d=2):    80ms
  âœ“ Embedding generation:     25ms
  âœ“ LLM inference (100 tok):  1200ms (WebGPU)
  âœ“ RAG complete:             1500ms

  âœ“ Storage: 2.1GB (model) + 15MB (graph)
  âœ“ Memory: ~3GB peak
```

### 10.4 Optimisations PrÃ©vues

**Phase 1 (PoC)** :
- ImplÃ©mentation basique
- Pas d'optimisation prÃ©maturÃ©e

**Phase 2 (Production)** :
- Cache LRU (nodes, embeddings, queries)
- Batch operations
- Web Workers (parallÃ©lisation)
- Index tuning (HNSW params)
- Model quantization (Q4, Q8)

---

## 11. Plan d'ImplÃ©mentation

### Phase 1 : Foundation + PoC (3 semaines)

**Objectif :** DÃ©mo end-to-end fonctionnelle

#### Sprint 1 : CozoDB + Graph Basics
**DurÃ©e :** 1 semaine

**TÃ¢ches :**
- [ ] Setup projet (dependencies)
- [ ] IntÃ©gration CozoDB (WASM)
- [ ] Domain layer : types.rs (Node, Edge)
- [ ] Port GraphPort (interface)
- [ ] Adapter CozoGraphAdapter (basique)
- [ ] CRUD nodes (create, get)
- [ ] Chiffrement age integration
- [ ] Tests unitaires

**DÃ©livrables :**
- âœ… Create/Get node fonctionne
- âœ… Chiffrement opÃ©rationnel
- âœ… Tests passent

#### Sprint 2 : WebLLM + Embeddings
**DurÃ©e :** 1 semaine

**TÃ¢ches :**
- [ ] IntÃ©gration WebLLM
- [ ] Download + cache model (Phi-3.5)
- [ ] Port LLMPort + EmbeddingPort
- [ ] Adapter WebLLMAdapter
- [ ] Adapter TransformersEmbedding
- [ ] Tests inference basique
- [ ] Mesure performance (latency, memory)

**DÃ©livrables :**
- âœ… LLM rÃ©pond Ã  des prompts simples
- âœ… Embeddings gÃ©nÃ©rÃ©s correctement
- âœ… Benchmarks de base

#### Sprint 3 : RAG Pipeline
**DurÃ©e :** 1 semaine

**TÃ¢ches :**
- [ ] ImplÃ©mentation vector search (HNSW)
- [ ] Graph traversal (Datalog)
- [ ] Domain : rag.rs (logique RAG)
- [ ] RAG orchestrator (TypeScript)
- [ ] Prompt builder
- [ ] Sauvegarde interactions
- [ ] UI playground (dÃ©mo)
- [ ] Tests end-to-end

**DÃ©livrables :**
- âœ… Question â†’ RÃ©ponse (RAG complet)
- âœ… DÃ©mo interactive
- âœ… Documentation

**CritÃ¨res de succÃ¨s Phase 1 :**
- âœ… RAG fonctionne end-to-end
- âœ… < 3s pour requÃªte complÃ¨te
- âœ… 1000 mÃ©moires gÃ©rÃ©es sans problÃ¨me
- âœ… Chiffrement vÃ©rifiÃ©
- âœ… DÃ©mo impressionnante

---

### Phase 2 : Production Features (4 semaines)

**Sprint 4-5 : API ComplÃ¨te + Relations**
- CRUD complet (update, delete)
- Graph traversal avancÃ© (shortest path, neighbors)
- Types de relations prÃ©dÃ©finis
- Batch operations
- Transactions

**Sprint 6-7 : Optimisations**
- Cache LRU
- Web Workers
- Index tuning
- Performance profiling
- Documentation complÃ¨te

**CritÃ¨res de succÃ¨s Phase 2 :**
- âœ… API stable et documentÃ©e
- âœ… 100K nÅ“uds gÃ©rÃ©s
- âœ… < 1.5s pour RAG query
- âœ… Tests coverage > 80%

---

### Phase 3 : Polish & Advanced (2 semaines)

**Sprint 8 : Advanced Features**
- RequÃªtes Datalog complexes
- Analytics (PageRank, clustering)
- Multi-model support (Llama, Mistral)
- Model switching (hot-swap)

**Sprint 9 : Documentation & Examples**
- Guide utilisateur complet
- API reference
- Tutoriaux
- Exemples d'applications
- Video dÃ©mo

---

## 12. RÃ©fÃ©rences

### 12.1 Technologies

**CozoDB**
- Docs: https://docs.cozodb.org/
- GitHub: https://github.com/cozodb/cozo
- Datalog: https://docs.cozodb.org/en/latest/queries.html

**WebLLM**
- Docs: https://webllm.mlc.ai/
- GitHub: https://github.com/mlc-ai/web-llm
- Models: https://github.com/mlc-ai/web-llm#available-models

**Transformers.js**
- Docs: https://huggingface.co/docs/transformers.js
- GitHub: https://github.com/xenova/transformers.js
- Models: https://huggingface.co/models?library=transformers.js

**OPFS**
- Spec: https://fs.spec.whatwg.org/
- MDN: https://developer.mozilla.org/en-US/docs/Web/API/File_System_API

**Age Encryption**
- Spec: https://age-encryption.org/
- Rust: https://docs.rs/age/

### 12.2 Concepts

**RAG (Retrieval-Augmented Generation)**
- Survey: https://arxiv.org/abs/2312.10997
- GraphRAG: https://www.microsoft.com/en-us/research/blog/graphrag/

**Vector Search**
- HNSW: https://arxiv.org/abs/1603.09320
- Embeddings: https://huggingface.co/spaces/mteb/leaderboard

**Graph Databases**
- Comparison: https://thedataquarry.com/blog/embedded-db-2/
- Datalog: https://en.wikipedia.org/wiki/Datalog

### 12.3 Hoddor

- Repository: https://github.com/Gatewatcher/hoddor
- Architecture hexagonale: Commit 9652512

---

## Annexes

### A. Glossaire

| Terme | DÃ©finition |
|-------|------------|
| **Node** | NÅ“ud dans le graphe (mÃ©moire, entitÃ©, concept) |
| **Edge** | Relation entre deux nÅ“uds |
| **Embedding** | ReprÃ©sentation vectorielle d'un texte (384 ou 768 dimensions) |
| **RAG** | Retrieval-Augmented Generation (recherche + gÃ©nÃ©ration LLM) |
| **HNSW** | Hierarchical Navigable Small World (algo vector search) |
| **Datalog** | Langage de requÃªte dÃ©claratif (CozoDB) |
| **OPFS** | Origin Private File System (storage navigateur) |
| **WebGPU** | API GPU pour navigateur |
| **SLM** | Small Language Model (< 10B params) |
| **Zero-Knowledge** | Serveur n'a jamais accÃ¨s aux donnÃ©es dÃ©chiffrÃ©es |

### B. FAQ

**Q: Pourquoi un LLM local plutÃ´t qu'une API cloud ?**
A: Privacy totale, coÃ»ts nuls, offline-capable, GDPR-compliant par design.

**Q: Performance comparÃ©e Ã  GPT-4 ?**
A: ModÃ¨les locaux (Phi, Llama 3B) moins capables mais suffisants pour 80% des cas. Trade-off privacy vs qualitÃ©.

**Q: Quelle taille de graphe supportÃ©e ?**
A: TestÃ© jusqu'Ã  100K nÅ“uds. Au-delÃ , optimisations nÃ©cessaires (partitionnement, index avancÃ©s).

**Q: Combien d'espace disque ?**
A: Model (~2-4GB) + Graph (~10MB par 1000 nÅ“uds) + Cache (~100MB). Total: ~3-5GB.

**Q: Compatible tous navigateurs ?**
A: WebGPU (Chrome 113+, Edge 113+). Safari/Firefox: WASM fallback (plus lent mais fonctionne).

**Q: Peut-on utiliser plusieurs modÃ¨les ?**
A: Oui, configuration runtime. Charger Phi-3.5 pour rapiditÃ©, Mistral-7B pour qualitÃ©.

---

## Changelog

| Version | Date | Changements |
|---------|------|-------------|
| 1.0 | 2025-10-20 | Version initiale |
| 2.0 | 2025-10-20 | Ajout WebLLM, refacto spec (moins de code, plus conceptuel) |

---

**FIN DE LA SPÃ‰CIFICATION**

*Document maintenu par l'Ã©quipe Hoddor. Pour questions : crÃ©er une issue sur GitHub.*
